{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82409c3a-5172-429d-9411-cad25079e1de",
   "metadata": {},
   "source": [
    "# Semi-structured eval: Long-context\n",
    "\n",
    "We will test retrival of table information from the `Semi-structured Reports` dataset using various methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363b9e4f-f15d-4283-84a7-d4ca0b7f6739",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U langchain langsmith langchain_benchmarks\n",
    "%pip install -U anthropic openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dcbfd5-5f0e-469d-b2b1-79b9c440306b",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0350e25a-c5b0-4b67-8257-6037ecc232df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from langchain_benchmarks import clone_public_dataset, registry\n",
    "from langchain_benchmarks.rag.tasks.semi_structured_reports import get_file_names\n",
    "\n",
    "# Task\n",
    "task = registry[\"Semi-structured Reports\"]\n",
    "\n",
    "# Files used\n",
    "paths = list(get_file_names())\n",
    "files = [str(p) for p in paths]\n",
    "\n",
    "### TODO: Replace when dataset is updated \n",
    "dir = \"/Users/rlm/Desktop/Eval_Sets/semi_structured_reports/\"\n",
    "files = [dir+f for f in os.listdir(dir) if f.endswith(\".pdf\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a723aa13-abeb-4839-8425-3591ad635893",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3122719-82b4-47ef-9dc8-3df9b73bec2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "texts = []\n",
    "for fi in files:\n",
    "    loader = PyPDFLoader(fi)\n",
    "    pdf_pages = loader.load()\n",
    "    texts.extend(pdf_pages)\n",
    "\n",
    "texts = [t.page_content for t in texts]\n",
    "text_string = ' /// New Document /// '.join(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6292b1-5aab-46bb-b03f-79087444835c",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa1e5b2f-6dda-42a0-95a7-bcfd1281c830",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chat_models import ChatAnthropic\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "def create_chain(model):\n",
    "\n",
    "    # Prompt template\n",
    "    template = \"\"\"Answer the question based only on the following context, which can include text and tables:\n",
    "    {context}\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    \n",
    "    chain = (\n",
    "            {\n",
    "                \"context\":  lambda x: text_string,\n",
    "                \"question\": RunnablePassthrough(),\n",
    "            }\n",
    "            | prompt\n",
    "            | model\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "\n",
    "    return chain\n",
    "    \n",
    "# OAI 128k\n",
    "model = ChatOpenAI(temperature=0, model=\"gpt-4-1106-preview\")\n",
    "chain_oai_128k = create_chain(model)\n",
    "\n",
    "# Anthropic 100k\n",
    "model = ChatAnthropic(temperature=0, model=\"claude-v1-100k\")\n",
    "chain_claude = create_chain(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791c28f8-56ea-47db-8417-596fffadd43d",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "900dada1-59d1-4a00-80f5-efe2387cef36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'oai_128k_e264e160-6b78-4e90-9d31-e1f8408c1d2f' at:\n",
      "https://smith.langchain.com/o/1fa8b1f4-fcb9-4072-9aa9-983e35ad61b8/projects/p/3b461515-facc-4c48-910d-f3987c892976?eval=true\n",
      "\n",
      "View all tests for Dataset Semi-Structured-Eval at:\n",
      "https://smith.langchain.com/o/1fa8b1f4-fcb9-4072-9aa9-983e35ad61b8/datasets/95f61109-029d-43a9-ae7d-ec1d53c6f723\n",
      "[------------------------------------->            ] 15/20"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain failed for example 8270a2d1-76a7-4ba6-ba85-c9439fa8c9dc with inputs {'question': \"What was the year-over-year change in Datadog's net income for the three months that ended September 30, 2023?\"}\n",
      "Error Type: RateLimitError, Message: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-1106-preview in organization org-beE7dFiWHsRELDAwjnWvVrhA on tokens per min (TPM): Limit 300000, Used 293648, Requested 36132. Please try again in 5.956s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[--------------------------------------->          ] 16/20"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain failed for example 4737f962-738c-496b-b4c7-46abdfd36f82 with inputs {'question': 'How much capitalized software expense did Datadog report for the three months that ended September 30, 2023?'}\n",
      "Error Type: RateLimitError, Message: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-1106-preview in organization org-beE7dFiWHsRELDAwjnWvVrhA on tokens per min (TPM): Limit 300000, Used 280605, Requested 36131. Please try again in 3.347s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-------------------------------------------->     ] 18/20"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain failed for example 7e0aa415-3f65-4078-afba-73c0d4237f0f with inputs {'question': 'How much did Datadog spend on R&D for the three months ended September 30,2023?'}\n",
      "Error Type: RateLimitError, Message: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-1106-preview in organization org-beE7dFiWHsRELDAwjnWvVrhA on tokens per min (TPM): Limit 300000, Used 266424, Requested 36124. Please try again in 509ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[------------------------------------------------->] 20/20\n",
      " Eval quantiles:\n",
      "                                0.25        0.5       0.75       mean  \\\n",
      "embedding_cosine_distance   0.032063   0.049692   0.066995   0.050126   \n",
      "faithfulness                0.100000   0.100000   0.100000   0.136364   \n",
      "score_string:accuracy       0.100000   0.700000   1.000000   0.652941   \n",
      "execution_time             10.165935  10.165935  10.165935  10.165935   \n",
      "\n",
      "                                mode  \n",
      "embedding_cosine_distance   0.007891  \n",
      "faithfulness                0.100000  \n",
      "score_string:accuracy       1.000000  \n",
      "execution_time             10.165935  \n",
      "View the evaluation results for project 'claude2_100k_e264e160-6b78-4e90-9d31-e1f8408c1d2f' at:\n",
      "https://smith.langchain.com/o/1fa8b1f4-fcb9-4072-9aa9-983e35ad61b8/projects/p/d4f62582-d832-4b46-b0cb-cd9d30d9ca62?eval=true\n",
      "\n",
      "View all tests for Dataset Semi-Structured-Eval at:\n",
      "https://smith.langchain.com/o/1fa8b1f4-fcb9-4072-9aa9-983e35ad61b8/datasets/95f61109-029d-43a9-ae7d-ec1d53c6f723\n",
      "[------------------------>                         ] 10/20"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain failed for example e0f62570-d458-4533-b81f-47fa12fe9525 with inputs {'question': 'How many bank failures occurred between 2021 and 2023?'}\n",
      "Error Type: InternalServerError, Message: Error code: 529 - {'error': {'type': 'overloaded_error', 'message': 'Overloaded'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[------------------------------------------------->] 20/20\n",
      " Eval quantiles:\n",
      "                                0.25        0.5       0.75       mean  \\\n",
      "embedding_cosine_distance   0.061142   0.081544   0.095727   0.083903   \n",
      "faithfulness                0.100000   0.300000   0.750000   0.420000   \n",
      "score_string:accuracy       0.100000   0.500000   0.800000   0.478947   \n",
      "execution_time             31.836878  31.836878  31.836878  31.836878   \n",
      "\n",
      "                                mode  \n",
      "embedding_cosine_distance   0.034193  \n",
      "faithfulness                0.100000  \n",
      "score_string:accuracy       0.100000  \n",
      "execution_time             31.836878  \n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from langsmith.client import Client\n",
    "\n",
    "from langchain_benchmarks.rag import get_eval_config\n",
    "\n",
    "\n",
    "def run_eval(chain, eval_run_name):\n",
    "    \"\"\"\n",
    "    Run eval\n",
    "    \"\"\"\n",
    "    client = Client()\n",
    "    test_run = client.run_on_dataset(\n",
    "        ### TODO: Replace with public dataset \n",
    "        dataset_name=\"Semi-Structured-Eval\",\n",
    "        llm_or_chain_factory=lambda: (lambda x: x[\"question\"]) | chain,\n",
    "        evaluation=get_eval_config(),\n",
    "        verbose=True,\n",
    "        project_name = eval_run_name\n",
    "    )\n",
    "\n",
    "\n",
    "# Experiments\n",
    "chain_map = {\n",
    "    \"oai_128k\": chain_oai_128k,\n",
    "    \"claude2_100k\": chain_claude,\n",
    "}\n",
    "\n",
    "run_id = str(uuid.uuid4())\n",
    "for project_name, chain in chain_map.items():\n",
    "    run_eval(chain, project_name+\"_\"+run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc85b876-e8ae-4c88-b43b-8b47d86166a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
